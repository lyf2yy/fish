# Ultralytics YOLO ğŸš€, GPL-3.0 license
# Default training settings and hyperparameters for medium-augmentation COCO training

task: detect  # inference task, i.e. detect, segment, classify
# mode: train  # YOLO mode, i.e. train, val, predict, export   # éœ€è¦ä¿®æ”¹ï¼Œ è®­ç»ƒæ¨¡å¼
mode: predict  # YOLO mode, i.e. train, val, predict, export   # éœ€è¦ä¿®æ”¹ï¼Œ é¢„æµ‹æ¨¡å¼

# Train settings -------------------------------------------------------------------------------------------------------
# model:  F:\pr_tmp\ultralytics_fish\ultralytics\yolo\v8\detect\yolov8n.pt # éœ€è¦ä¿®æ”¹ ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
# model:  yolov8n.yaml #  # éœ€è¦æŒ‡å®š   ä¸ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
model:  F:\pr_tmp\ultralytics_fish\ultralytics\yolo\v8\detect\bccd\04137\weights\best.pt # è®­ç»ƒä¸­æœ€ä½³çš„æ¨¡å‹æƒé‡

data:  bccd.yaml # path to data file, i.e. i.e. coco128.yaml   # éœ€è¦æŒ‡å®š

center_box: True #æ ‡æ³¨boxåæ ‡xywhï¼Œxyæ˜¯å¦æ˜¯boxä¸­å¿ƒ(è¿˜æ˜¯å·¦ä¸Šè§’åæ ‡)ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼

updateBN: False #ç¨€ç–åŒ–BNçš„gammaå‚æ•°
pruneTrain: False #å‰ªæååˆæ¬¡å¾®è°ƒc

epochs: 50  # number of epochs to train for
patience: 10  # epochs to wait for no observable improvement for early stopping of training
batch: 1 # number of images per batch (-1 for AutoBatch)  
imgsz: 960 # size of input images as integer or w,h, list or int
save: True  # save train checkpoints and predict results
save_period: 1 # Save checkpoint every x epochs (disabled if < 1)
cache: False  # True/ram, disk or False. Use cache for data loading
device: 0 # device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
workers: 0  # number of worker threads for data loading (per RANK if DDP)

project:  "bccd" # project name   # éœ€è¦æŒ‡å®š
name:  "0413" # experiment name   # éœ€è¦æŒ‡å®š

all_classes: [] #éœ€è¦æ£€æµ‹å“ªäº›ç±»åˆ« [0, 2, 3]. ä¸ºç©ºé»˜è®¤æ£€æµ‹å…¨éƒ¨ç±»åˆ«

single_channel: False #æ˜¯å¦è¾“å…¥ç°åº¦å›¾,  # éœ€è¦æŒ‡å®š æ˜¯å¦æ˜¯ç°åº¦å›¾åƒ

exist_ok: False  # whether to overwrite existing experimentï¼Œlogæ–‡ä»¶æ˜¯å¦è¦†ç›–ï¼Œå¦åˆ™åˆ›å»ºæ–°çš„æ–‡ä»¶
pretrained: False  # whether to use a pretrained model #

optimizer: SGD  # optimizer to use, choices=['SGD', 'Adam', 'AdamW', 'RMSProp']
verbose: True  # whether to print verbose output
seed: 0  # random seed for reproducibility
deterministic: False  # whether to enable deterministic mode

single_cls: False  # train multi-class data as single-class,æ‰€æœ‰çš„ç±»éƒ½ä½œä¸ºå‰æ™¯ç±»ï¼Œåªçœ‹æ˜¯å¦æ£€æµ‹å‡ºæ¥ï¼Œä¸çœ‹åˆ†ç±»
image_weights: True  # use weighted image selection for training #æ•ˆæœä¸å¥½çš„å›¾ç‰‡ä¸‹ä¸€epochä¸­æé«˜æƒé‡
rect: True  # support rectangular training if mode='train' #ä¸ºFalseä¼šæŠŠå›¾ç‰‡paddingä¸ºæ­£æ–¹å½¢ï¼Œä¸ºTrueæ—¶åªä¼špaddingä¸º32çš„å€æ•°ï¼ŒèŠ‚çœè®¡ç®—é‡
cos_lr: True  # use cosine learning rate scheduler ä½™å¼¦è¡°å‡
cos_step: 20  # use cosine learning rate scheduler ä½™å¼¦è¡°å‡
close_mosaic: 10  # disable mosaic augmentation for final 10 epochs #æœ€å10ä¸ªepochå…³é—­mosaicå¢å¼º
resume: False  # resume training from last checkpoint #ä½¿ç”¨last.pt æ¥ç€è®­ç»ƒ
min_memory: False  # minimize memory footprint loss function, choices=[False, True, <roll_out_thr>]
# Segmentation
overlap_mask: True  # masks should overlap during training (segment train only)
mask_ratio: 4  # mask downsample ratio (segment train only)
# Classification
dropout: 0.0  # use dropout regularization (classify train only)


# Val/Test settings ----------------------------------------------------------------------------------------------------
val: True  # validate/test during training
split: val  # dataset split to use for validation, i.e. 'val', 'test' or 'train'
save_json: False  # save results to JSON file
save_hybrid: False  # save hybrid version of labels (labels + additional predictions)
conf:   # object confidence threshold for detection (default 0.25 predict, 0.001 val)
iou: 0.3  # intersection over union (IoU) threshold for NMS
max_det: 100  # maximum number of detections per image
half: False  # use half precision (FP16)
dnn: False  # use OpenCV DNN for ONNX inference
plots: True  # save plots during train/val

# Prediction settings --------------------------------------------------------------------------------------------------
# source: /home/lead/data/Conv_light/allimgs # source directory for images or videos
source: F:\pr_tmp\ultralytics_fish\data\images\val # source directory for images or videos éœ€è¦é¢„æµ‹å›¾ç‰‡çš„è·¯å¾„     # éœ€è¦æŒ‡å®š
show: False  # show results if possible
save_txt: True  # save results as .txt file #æ˜¯å¦ä¿å­˜txt
save_conf: True  # save results with confidence scores#ä¿å­˜ç½®ä¿¡åº¦åˆ°txt
save_crop: False  # save cropped images with results å°†patchæŒ‰ç…§ç±»åˆ«å­˜å‚¨
hide_labels: False  # hide labels# å›¾ç‰‡ä¸­ä¸æ˜¾ç¤ºlabelå’Œç½®ä¿¡åº¦
hide_conf: False  # hide confidence scores #å›¾ç‰‡ä¸­ä¸æ˜¾ç¤ºç½®ä¿¡åº¦åˆ†æ•°
vid_stride: 1  # video frame-rate stride #è§†é¢‘çš„å¸§ç‡
line_thickness: 3  # bounding box thickness (pixels) #æ¡†çš„åƒç´ å€¼
visualize: False  # visualize model features #å¯è§†åŒ–
augment: False  # apply image augmentation to prediction sources é¢„æµ‹æ—¶æ•°æ®å¢å¼º
agnostic_nms: False  # class-agnostic NMS #ç±»é—´NMS,æ˜¯å¦è¦é€šè¿‡iouæŠ‘åˆ¶ä¸åŒç±»åˆ«çš„box, ä¸ºTrueæ—¶ä¸åŒºåˆ†ç±»åˆ«
classes:  #  class=0, or class=[0,2,3] é¢„æµ‹æ—¶å€™åªé¢„æµ‹classesç±»åˆ«ï¼Œå¿½ç•¥å…¶ä»–ç±»åˆ«
retina_masks: False  # use high-resolution segmentation masks åˆ†å‰²ä»»åŠ¡
boxes: True  # Show boxes in segmentation predictions åˆ†å‰²ä»»åŠ¡

# Export settings ------------------------------------------------------------------------------------------------------
format: torchscript  # format to export to #å¯¼å‡ºæ ¼å¼ æ˜¯torchscripts
keras: False  # use Keras #
optimize: False  # TorchScript: optimize for mobile #
int8: False  # CoreML/TF INT8 quantization #é‡åŒ–ä¸ºint8
dynamic: False  # ONNX/TF/TensorRT: dynamic axes #åŠ¨æ€è¾“å…¥
simplify: True  # ONNX: simplify model #æ˜¯å¦ç®€åŒ–onnxç»“æ„
opset: 11 # ONNX: opset version (optional)# é»˜è®¤ç‰ˆæœ¬
workspace: 4  # TensorRT: workspace size (GB)
nms: False  # CoreML: add NMS

# Hyperparameters ------------------------------------------------------------------------------------------------------
lr0: 0.01  # initial learning rate (i.e. SGD=1E-2, Adam=1E-3)
lrf: 0.01  # final learning rate (lr0 * lrf)
momentum: 0.937  # SGD momentum/Adam beta1
weight_decay: 0.0005  # optimizer weight decay 5e-4
warmup_epochs: 3.0  # warmup epochs (fractions ok)
warmup_momentum: 0.8  # warmup initial momentum
warmup_bias_lr: 0.1  # warmup initial bias lr
box: 7.5  # box loss gain
cls: 10  # cls loss gain (scale with pixels)
dfl: 1.5  # dfl loss gain
topk: 10
# dfl: 3.0  # dfl loss gain
fl_gamma: 0.0  # focal loss gamma  0-1.0
label_smoothing: 0  # label smoothing (fraction)
nbs: 64  # nominal batch size
hsv_h: 0.015  # image HSV-Hue augmentation (fraction)
hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)
hsv_v: 0.4  # image HSV-Value augmentation (fraction)
degrees: 0.0  # image rotation (+/- deg) #0-180è§’åº¦
translate: 0.0  # image translation (+/- fraction)
scale: 0.0  # image scale (+/- gain)
shear: 0.0  # image shear (+/- deg)#0-180è§’åº¦
perspective: 0.0  # image perspective (+/- fraction), range 0-0.001
flipud: 0.0  # image flip up-down (probability)
fliplr: 0.0  # image flip left-right (probability)
Lumenchance: 0.0  # éšæœºæ¦‚ç‡ä¼½é©¬å˜æ¢ä¿®æ”¹ç°åº¦å€¼
HeightCrop: 0.0 #éšæœºè£å‰ªé«˜åº¦ï¼Œå¢åŠ å›¾åƒçš„å®½é«˜æ¯”å¤šæ ·æ€§
mosaic: 1.0  # image mosaic (probability)
# mosaic: 0.0  # image mosaic (probability)
mixup: 0.0  # image mixup (probability)
copy_paste: 0.0  # segment copy-paste (probability)

Noisemean: 0.0 #é«˜æ–¯å™ªå£°å‚æ•°
Noisevariance: 1.0
Noiseamplitude: 10.0
Noisep: 0.0


# Custom config.yaml ---------------------------------------------------------------------------------------------------
cfg:  # for overriding defaults.yaml

# Debug, do not modify -------------------------------------------------------------------------------------------------
v5loader: False  # use legacy YOLOv5 dataloader

# Tracker settings ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml  # tracker type, ['botsort.yaml', 'bytetrack.yaml']
